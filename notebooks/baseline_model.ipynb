{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b767d5ad-c4b1-40da-89d2-96ad833e9d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d1e69-b03d-4ab3-ae68-35104fc6d77b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compressing the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ce0d46-a878-48ba-b797-4b455f32cfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import cupy\n",
    "import cudf\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f834dfd-762d-4fe1-8f58-433ee3ffc8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for the preprocessing\n",
    "DATA_DIR = \"/home/silo1/mas322/amex-default-prediction/\"\n",
    "PROCESS_DATA = True\n",
    "NUM_SPLITS = 10\n",
    "NUM_FILES_TEST = 20\n",
    "PAD_CUSTOMER_TO_13_ROWS = True\n",
    "NUM_CATEGORICAL_COLUMNS = 11\n",
    "COLS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68', 'D_63', 'D_64', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'B_20', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_115', 'D_118', 'D_119', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
    "DEV = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9c38a-26f6-4685-bea5-af1c7df99a1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Formatting the data for use in RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c2d4f-5ba2-453a-b823-dbf2d4873f63",
   "metadata": {},
   "source": [
    "We will be using [Raddar's denoised](https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format) dataset, which is stored on disk as `train.parquet` and `test.parquet` in `$DATA_DIR/derived/`. We also have the original raw data in `$DATA_DIR/raw/train_data.csv` and `$DATA_DIR/raw/test_data.csv`. The denoised dataset from Raddar has already mapped the different categorical entries to numerical integer indices.\n",
    "\n",
    "In this section, we will process this data to split it into `NUM_SPLITS` and store seperate NumPy files on disk of shape `num_of_customers_in_split x 13 x 188`. These NumPy files will have the categorical values changes to numeric where each category is mapped to a distinct integer, even `NA`s. The `NA` in the numeric columns will be replaced by `-.5`. The preprocessing here is based on [this GRU starter blogpost](https://www.kaggle.com/code/cdeotte/tensorflow-gru-starter-0-790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33f907a-0ae7-4521-8e76-08b6211785da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if PROCESS_DATA:\n",
    "    for f in ['train_data', 'test_data', 'train_labels']:\n",
    "        print(f\"Converting {f}\")\n",
    "        df = pd.read_csv(os.path.join(dataset_dir, \"raw\", f\"{f}.csv\"))\n",
    "        df.to_feather(os.path.join(dataset_dir, \"derived\", f\"{f}.feather\"))\n",
    "        del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a62266-ce04-46c0-b533-c85184abddb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           customer_ID         S_2       P_2  D_39       B_1       B_2  \\\n",
       "0 -4532153018459703766  2017-03-09  0.938469     0  0.008724  1.006838   \n",
       "1 -4532153018459703766  2017-04-07  0.936665     0  0.004923  1.000653   \n",
       "2 -4532153018459703766  2017-05-28  0.954180     3  0.021655  1.009672   \n",
       "3 -4532153018459703766  2017-06-13  0.960384     0  0.013683  1.002700   \n",
       "4 -4532153018459703766  2017-07-16  0.947248     0  0.015193  1.000727   \n",
       "\n",
       "        R_1       S_3  D_41       B_3  ... D_136  D_137  D_138  D_139  D_140  \\\n",
       "0  0.009228  0.124035   0.0  0.004709  ...    -1     -1     -1      0      0   \n",
       "1  0.006151  0.126750   0.0  0.002714  ...    -1     -1     -1      0      0   \n",
       "2  0.006815  0.123977   0.0  0.009423  ...    -1     -1     -1      0      0   \n",
       "3  0.001373  0.117169   0.0  0.005531  ...    -1     -1     -1      0      0   \n",
       "4  0.007605  0.117325   0.0  0.009312  ...    -1     -1     -1      0      0   \n",
       "\n",
       "   D_141  D_142 D_143     D_144  D_145  \n",
       "0    0.0   <NA>     0  0.000610      0  \n",
       "1    0.0   <NA>     0  0.005492      0  \n",
       "2    0.0   <NA>     0  0.006986      0  \n",
       "3    0.0   <NA>     0  0.006527      0  \n",
       "4    0.0   <NA>     0  0.008126      0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if PROCESS_DATA:\n",
    "    df = cudf.read_parquet(os.path.join(DATA_DIR, \"derived\", \"train.parquet\"))\n",
    "    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "df.head() if PROCESS_DATA else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454076ac-9f1a-43e5-a40f-6c1796cc8660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas322/anaconda3/envs/cudf-torch/lib/python3.10/site-packages/cudf/io/feather.py:15: UserWarning: Using CPU via PyArrow to read feather dataset, this may be GPU accelerated in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 458913 train targets\n",
      "There are 190 train dataframe columns\n",
      "There are 458913 unique customers in train.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>...</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126749977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123976685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117324777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531446</th>\n",
       "      <td>-8425848485496994175</td>\n",
       "      <td>0.979333</td>\n",
       "      <td>14</td>\n",
       "      <td>0.020818</td>\n",
       "      <td>0.828199</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.090742894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025139</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531447</th>\n",
       "      <td>-8425848485496994175</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>10</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.812610</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.079886191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023691</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531448</th>\n",
       "      <td>-8425848485496994175</td>\n",
       "      <td>0.983019</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.815422</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.100502573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531449</th>\n",
       "      <td>-8425848485496994175</td>\n",
       "      <td>0.969861</td>\n",
       "      <td>15</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>1.003541</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.101802148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531450</th>\n",
       "      <td>-8425848485496994175</td>\n",
       "      <td>0.982175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.992880</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.119164906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5531451 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_ID       P_2  D_39       B_1       B_2       R_1  \\\n",
       "0       -4532153018459703766  0.938469     0  0.008724  1.006838  0.009228   \n",
       "1       -4532153018459703766  0.936665     0  0.004923  1.000653  0.006151   \n",
       "2       -4532153018459703766  0.954180     3  0.021655  1.009672  0.006815   \n",
       "3       -4532153018459703766  0.960384     0  0.013683  1.002700  0.001373   \n",
       "4       -4532153018459703766  0.947248     0  0.015193  1.000727  0.007605   \n",
       "...                      ...       ...   ...       ...       ...       ...   \n",
       "5531446 -8425848485496994175  0.979333    14  0.020818  0.828199  0.003487   \n",
       "5531447 -8425848485496994175  0.984907    10  0.007209  0.812610  0.005904   \n",
       "5531448 -8425848485496994175  0.983019    15  0.013151  0.815422  0.003457   \n",
       "5531449 -8425848485496994175  0.969861    15  0.009855  1.003541  0.005117   \n",
       "5531450 -8425848485496994175  0.982175     0  0.000077  0.992880  0.000809   \n",
       "\n",
       "                 S_3  D_41       B_3  D_42  ... D_139  D_140  D_141 D_142  \\\n",
       "0        0.124035157   0.0  0.004709  <NA>  ...     0      0    0.0  <NA>   \n",
       "1        0.126749977   0.0  0.002714  <NA>  ...     0      0    0.0  <NA>   \n",
       "2        0.123976685   0.0  0.009423  <NA>  ...     0      0    0.0  <NA>   \n",
       "3        0.117169224   0.0  0.005531  <NA>  ...     0      0    0.0  <NA>   \n",
       "4        0.117324777   0.0  0.009312  <NA>  ...     0      0    0.0  <NA>   \n",
       "...              ...   ...       ...   ...  ...   ...    ...    ...   ...   \n",
       "5531446  0.090742894   0.0  0.025139  <NA>  ...     0      0    0.0  <NA>   \n",
       "5531447  0.079886191   0.0  0.023691  <NA>  ...     0      0    0.0  <NA>   \n",
       "5531448  0.100502573   0.0  0.012343  <NA>  ...     0      0    0.0  <NA>   \n",
       "5531449  0.101802148   0.0  0.008578  <NA>  ...     0      0    0.0  <NA>   \n",
       "5531450  0.119164906   0.0  0.014092  <NA>  ...     0      0    0.0  <NA>   \n",
       "\n",
       "        D_143     D_144  D_145  year  month  day  \n",
       "0           0  0.000610      0    17      3    9  \n",
       "1           0  0.005492      0    17      4    7  \n",
       "2           0  0.006986      0    17      5   28  \n",
       "3           0  0.006527      0    17      6   13  \n",
       "4           0  0.008126      0    17      7   16  \n",
       "...       ...       ...    ...   ...    ...  ...  \n",
       "5531446     0  0.001498      0    17     11    5  \n",
       "5531447     0  0.008225      0    17     12   23  \n",
       "5531448     0  0.006773      0    18      1    6  \n",
       "5531449     0  0.001168      0    18      2    6  \n",
       "5531450     0  0.003184      0    18      3   14  \n",
       "\n",
       "[5531451 rows x 192 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if PROCESS_DATA:\n",
    "    # LOAD TARGETS\n",
    "    targets = cudf.read_feather(os.path.join(DATA_DIR, 'derived', 'train_labels.feather'))\n",
    "    targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    print(f'There are {targets.shape[0]} train targets')\n",
    "\n",
    "    # GET TRAIN COLUMN NAMES\n",
    "    train = cudf.read_csv(os.path.join(DATA_DIR, 'raw', 'train_data.csv'), nrows=1)\n",
    "    T_COLS = train.columns\n",
    "    print(f'There are {len(T_COLS)} train dataframe columns')\n",
    "\n",
    "    customers = df.customer_ID.unique().values.flatten()\n",
    "    print(f'There are {len(customers)} unique customers in train.')\n",
    "\n",
    "    # extract the Y, M and D from the date column, then sort by time (after customer_ID)\n",
    "    df.S_2 = cudf.to_datetime(df.S_2)\n",
    "    df['year'] = (df.S_2.dt.year-2000).astype('int8')\n",
    "    df['month'] = (df.S_2.dt.month).astype('int8')\n",
    "    df['day'] = (df.S_2.dt.day).astype('int8')\n",
    "    del df['S_2']\n",
    "\n",
    "df if PROCESS_DATA else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e9750-2286-43d0-8a86-36f5c6d19fec",
   "metadata": {},
   "source": [
    "Numerical columns are padded with `-3`, as that is not used anywhere in the data. Categorical columns are padded with `-2`. Notes that this gives a gap for feature `D_63`, which seemingly is not missing any values:\n",
    "```\n",
    "Feature B_30: min=-1, max=2\n",
    "\tNan count: 0\n",
    "Feature B_38: min=-1, max=7\n",
    "\tNan count: 0\n",
    "Feature D_114: min=-1, max=1\n",
    "\tNan count: 0\n",
    "Feature D_116: min=-1, max=1\n",
    "\tNan count: 0\n",
    "Feature D_117: min=-1, max=7\n",
    "\tNan count: 0\n",
    "Feature D_120: min=-1, max=1\n",
    "\tNan count: 0\n",
    "Feature D_126: min=-1, max=2\n",
    "\tNan count: 0\n",
    "Feature D_66: min=-1, max=1\n",
    "\tNan count: 0\n",
    "Feature D_68: min=-1, max=6\n",
    "\tNan count: 0\n",
    "Feature D_63: min=0, max=5\n",
    "\tNan count: 0\n",
    "Feature D_64: min=-1, max=3\n",
    "\tNan count: 0\n",
    "```\n",
    "Also, code for checking if any conflicts with padded values:\n",
    "```\n",
    "for c in T_COLS:\n",
    "    if c == 'S_2': continue\n",
    "    print(c, df[df[c] == -2].shape[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1936d111-2443-42b6-afd6-febc7d59319b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>...</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126749977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123976685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4532153018459703766</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117324777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965864</th>\n",
       "      <td>-55748515817554379</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965865</th>\n",
       "      <td>-2688056353488173321</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965866</th>\n",
       "      <td>8782972297529978422</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965867</th>\n",
       "      <td>7318692200354110648</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965868</th>\n",
       "      <td>-2772238107193833475</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5965869 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_ID       P_2  D_39       B_1       B_2       R_1  \\\n",
       "0       -4532153018459703766  0.938469     0  0.008724  1.006838  0.009228   \n",
       "1       -4532153018459703766  0.936665     0  0.004923  1.000653  0.006151   \n",
       "2       -4532153018459703766  0.954180     3  0.021655  1.009672  0.006815   \n",
       "3       -4532153018459703766  0.960384     0  0.013683  1.002700  0.001373   \n",
       "4       -4532153018459703766  0.947248     0  0.015193  1.000727  0.007605   \n",
       "...                      ...       ...   ...       ...       ...       ...   \n",
       "5965864   -55748515817554379 -3.000000    -3 -3.000000 -3.000000 -3.000000   \n",
       "5965865 -2688056353488173321 -3.000000    -3 -3.000000 -3.000000 -3.000000   \n",
       "5965866  8782972297529978422 -3.000000    -3 -3.000000 -3.000000 -3.000000   \n",
       "5965867  7318692200354110648 -3.000000    -3 -3.000000 -3.000000 -3.000000   \n",
       "5965868 -2772238107193833475 -3.000000    -3 -3.000000 -3.000000 -3.000000   \n",
       "\n",
       "                 S_3  D_41       B_3  D_42  ... D_139  D_140  D_141  D_142  \\\n",
       "0        0.124035157   0.0  0.004709  <NA>  ...     0      0    0.0   <NA>   \n",
       "1        0.126749977   0.0  0.002714  <NA>  ...     0      0    0.0   <NA>   \n",
       "2        0.123976685   0.0  0.009423  <NA>  ...     0      0    0.0   <NA>   \n",
       "3        0.117169224   0.0  0.005531  <NA>  ...     0      0    0.0   <NA>   \n",
       "4        0.117324777   0.0  0.009312  <NA>  ...     0      0    0.0   <NA>   \n",
       "...              ...   ...       ...   ...  ...   ...    ...    ...    ...   \n",
       "5965864         -3.0  -3.0 -3.000000  -3.0  ...    -3     -3   -3.0   -3.0   \n",
       "5965865         -3.0  -3.0 -3.000000  -3.0  ...    -3     -3   -3.0   -3.0   \n",
       "5965866         -3.0  -3.0 -3.000000  -3.0  ...    -3     -3   -3.0   -3.0   \n",
       "5965867         -3.0  -3.0 -3.000000  -3.0  ...    -3     -3   -3.0   -3.0   \n",
       "5965868         -3.0  -3.0 -3.000000  -3.0  ...    -3     -3   -3.0   -3.0   \n",
       "\n",
       "        D_143     D_144  D_145  year  month  day  \n",
       "0           0  0.000610      0    17      3    9  \n",
       "1           0  0.005492      0    17      4    7  \n",
       "2           0  0.006986      0    17      5   28  \n",
       "3           0  0.006527      0    17      6   13  \n",
       "4           0  0.008126      0    17      7   16  \n",
       "...       ...       ...    ...   ...    ...  ...  \n",
       "5965864    -3 -3.000000     -3    -3     -3   -3  \n",
       "5965865    -3 -3.000000     -3    -3     -3   -3  \n",
       "5965866    -3 -3.000000     -3    -3     -3   -3  \n",
       "5965867    -3 -3.000000     -3    -3     -3   -3  \n",
       "5965868    -3 -3.000000     -3    -3     -3   -3  \n",
       "\n",
       "[5965869 rows x 192 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not all the customers have 13 rows, so pad all the ones with fewer rows\n",
    "# df[['customer_ID']].groupby('customer_ID').customer_ID.agg('count').mean()\n",
    "\n",
    "CATS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68'] + ['D_63','D_64']\n",
    "\n",
    "if PAD_CUSTOMER_TO_13_ROWS and PROCESS_DATA:\n",
    "    tmp = df[['customer_ID']].groupby('customer_ID').customer_ID.agg('count')\n",
    "    more = cupy.array([], dtype='int64') \n",
    "    for j in range(1, 13):\n",
    "        i = tmp.loc[tmp == j].index.values\n",
    "        more = cupy.concatenate([more, cupy.repeat(i, 13-j)])\n",
    "    df_pad = df.iloc[:len(more)].copy().fillna(0)\n",
    "    df_pad = df_pad * 0 - 3 #pad numerical columns with -3\n",
    "    df_pad[CATS] = (df_pad[CATS] * 0 - 2).astype('int8') #pad categorical columns with -2\n",
    "    df_pad['customer_ID'] = more\n",
    "    df = cudf.concat([df, df_pad], axis = 0, ignore_index=True)\n",
    "    \n",
    "    del tmp, df_pad\n",
    "    gc.collect()\n",
    "df if PAD_CUSTOMER_TO_13_ROWS and PROCESS_DATA else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10dd58d4-a8fc-41a0-89f5-207dc850d3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not all the time-series are of length 13\n",
    "df[['customer_ID']].groupby('customer_ID').customer_ID.agg('count').mean() if PROCESS_DATA else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33c27ec-b7d8-4e44-89c8-ce080461c11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge the targets\n",
    "if PROCESS_DATA:\n",
    "    df = df.merge(targets, on='customer_ID', how='left')\n",
    "    df.target = df.target.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475da9cc-0ac5-42be-bfb6-8d573c55d4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>B_30</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_66</th>\n",
       "      <th>D_68</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9223358381327749917</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965864</th>\n",
       "      <td>9223350112805974911</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965865</th>\n",
       "      <td>9223350112805974911</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965866</th>\n",
       "      <td>9223350112805974911</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965867</th>\n",
       "      <td>9223350112805974911</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965868</th>\n",
       "      <td>9223350112805974911</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5965869 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_ID  B_30  B_38  D_114  D_116  D_117  D_120  D_126  \\\n",
       "0       -9223358381327749917     1     6      1      0      0      1      2   \n",
       "1       -9223358381327749917     1     6      1      0      3      1      2   \n",
       "2       -9223358381327749917     1     3      1      0      3      1      2   \n",
       "3       -9223358381327749917     1     3      1      0      0      1      2   \n",
       "4       -9223358381327749917     1     3      1      0      0      1      2   \n",
       "...                      ...   ...   ...    ...    ...    ...    ...    ...   \n",
       "5965864  9223350112805974911     1     6      1      0      5      0      2   \n",
       "5965865  9223350112805974911     1     6      1      0      5      0      2   \n",
       "5965866  9223350112805974911     1     7      1      0      5      0      2   \n",
       "5965867  9223350112805974911     1     7      1      0      5      0      2   \n",
       "5965868  9223350112805974911     1     6      1      0      5      0      2   \n",
       "\n",
       "         D_66  D_68  ...  D_137  D_138  D_139  D_140  D_141 D_142 D_143  \\\n",
       "0          -1     2  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "1          -1     2  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "2          -1     2  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "3          -1     2  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "4          -1     3  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "...       ...   ...  ...    ...    ...    ...    ...    ...   ...   ...   \n",
       "5965864    -1     6  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "5965865    -1     6  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "5965866    -1     6  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "5965867    -1     6  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "5965868    -1     6  ...     -1     -1      0      0    0.0  <NA>     0   \n",
       "\n",
       "            D_144  D_145  target  \n",
       "0        0.004787      0       1  \n",
       "1        0.003442      0       1  \n",
       "2        0.003340      0       1  \n",
       "3        0.007556      0       1  \n",
       "4        0.005299      0       1  \n",
       "...           ...    ...     ...  \n",
       "5965864  0.003152      0       1  \n",
       "5965865  0.002049      0       1  \n",
       "5965866  0.000250      0       1  \n",
       "5965867  0.007640      0       1  \n",
       "5965868  0.005816      0       1  \n",
       "\n",
       "[5965869 rows x 190 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by customer ID, then by data. Then rearrange columns with 11 cats first\n",
    "if PROCESS_DATA:\n",
    "    df = df.sort_values(['customer_ID', 'year', 'month', 'day']).reset_index(drop = True)\n",
    "    df = df.drop(['year', 'month', 'day'], axis=1)\n",
    "    \n",
    "    COLS = list(df.columns[1:])\n",
    "    COLS = ['customer_ID'] + CATS + [c for c in COLS if c not in CATS]\n",
    "    df = df[COLS]\n",
    "df if PROCESS_DATA else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b0dddc-ffe1-46cd-bb94-6d84bce4e322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fill remaining NaNs with -0.5\n",
    "df = df.fillna(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "375aa74d-f3b8-412e-9752-5cecc465e61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 10] Saving data with 596583 rows...\n",
      "[2 / 10] Saving data with 596583 rows...\n",
      "[3 / 10] Saving data with 596583 rows...\n",
      "[4 / 10] Saving data with 596583 rows...\n",
      "[5 / 10] Saving data with 596583 rows...\n",
      "[6 / 10] Saving data with 596583 rows...\n",
      "[7 / 10] Saving data with 596583 rows...\n",
      "[8 / 10] Saving data with 596583 rows...\n",
      "[9 / 10] Saving data with 596583 rows...\n",
      "[10 / 10] Saving data with 596622 rows...\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_SPLITS):\n",
    "    lower = (len(customers) // NUM_SPLITS) * i\n",
    "    upper = (len(customers) // NUM_SPLITS) * (i + 1)\n",
    "    if i == NUM_SPLITS - 1:\n",
    "        upper = len(customers)\n",
    "        \n",
    "    sub_df = df[df.customer_ID.isin(customers[lower:upper])]\n",
    "    print(f\"[{i + 1} / {NUM_SPLITS}] Saving data with {len(sub_df)} rows...\")\n",
    "    \n",
    "    sub_targets = sub_df[['customer_ID', 'target']].drop_duplicates().sort_index()\n",
    "    sub_targets.to_parquet(os.path.join(DATA_DIR, 'derived', 'processed-splits', f\"train-targets_{i}.parquet\"))\n",
    "    \n",
    "    # remove the customer ID and the target column 190 -> 188\n",
    "    sub_data = sub_df.iloc[:, 1:-1].values.reshape((-1, 13, 188))\n",
    "    cupy.save(os.path.join(DATA_DIR, \"derived\", \"processed-splits\", f\"train-data_{i}.npy\"), sub_data.astype('float32'))\n",
    "    \n",
    "    del sub_df, sub_targets, sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55e10ca-9870-4ffb-afdc-84064e9453a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# categorical values already converted to numeric integers, but what happened to the missing values? Were there none for D_63?\n",
    "# cats = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68', 'D_63', 'D_64']\n",
    "# for c in cats:\n",
    "#     print(f\"Feature {c}: min={df[c].min()}, max={df[c].max()}\")\n",
    "#     print(f\"\\tNan count: {df[c].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accce0f1-1a31-4de6-85b9-95da1314f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2419fab7-03d3-4728-911b-b654fe99ea69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Formatting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c50d67-fe99-4432-b495-298a1034952f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CALCULATE SIZE OF EACH SEPARATE FILE\n",
    "def get_rows(customers, train, num_files = 10, verbose = ''):\n",
    "    \"\"\"\n",
    "    References:\n",
    "      - https://www.kaggle.com/code/cdeotte/tensorflow-gru-starter-0-790\n",
    "    \"\"\"\n",
    "    chunk = len(customers)//num_files\n",
    "    if verbose != '':\n",
    "        print(f'We will split {verbose} data into {num_files} separate files.')\n",
    "        print(f'There will be {chunk} customers in each file (except the last file).')\n",
    "        print('Below are number of rows in each file:')\n",
    "    rows = []\n",
    "\n",
    "    for k in range(num_files):\n",
    "        if k==num_filesm-1: cc = customers[k*chunk:]\n",
    "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
    "        s = train.loc[train.customer_ID.isin(cc)].shape[0]\n",
    "        rows.append(s)\n",
    "    if verbose != '': print( rows )\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a057d95-95b1-4486-ae7f-a625c10d8a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/home/silo1/mas322/amex-default-prediction/raw/test_data.csv could not be resolved to any files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PROCESS_DATA:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# GET TEST COLUMN NAMES\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     test \u001b[38;5;241m=\u001b[39m \u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     T_COLS \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(T_COLS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test dataframe columns\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudf-torch/lib/python3.10/site-packages/nvtx/nvtx.py:101\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/cudf-torch/lib/python3.10/site-packages/cudf/io/csv.py:76\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, prefix, mangle_dupe_cols, dtype, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, dayfirst, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, comment, delim_whitespace, byte_range, use_python_file_object, storage_options, bytes_per_thread)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_single_filepath_or_buffer:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`read_csv` does not yet support reading multiple files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m     )\n\u001b[0;32m---> 76\u001b[0m filepath_or_buffer, compression \u001b[38;5;241m=\u001b[39m \u001b[43mioutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reader_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43miotypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringIO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNativeFile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_python_file_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_python_file_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbytes_per_thread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbytes_per_thread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_scalar(na_values):\n\u001b[1;32m     86\u001b[0m     na_values \u001b[38;5;241m=\u001b[39m [na_values]\n",
      "File \u001b[0;32m~/anaconda3/envs/cudf-torch/lib/python3.10/site-packages/cudf/utils/ioutils.py:1684\u001b[0m, in \u001b[0;36mget_reader_filepath_or_buffer\u001b[0;34m(path_or_data, compression, mode, fs, iotypes, use_python_file_object, open_file_options, allow_raw_text_input, storage_options, bytes_per_thread)\u001b[0m\n\u001b[1;32m   1682\u001b[0m             path_or_data \u001b[38;5;241m=\u001b[39m paths \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m paths[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1683\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_raw_text_input:\n\u001b[0;32m-> 1684\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1685\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be resolved to any files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1686\u001b[0m             )\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1689\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /home/silo1/mas322/amex-default-prediction/raw/test_data.csv could not be resolved to any files"
     ]
    }
   ],
   "source": [
    "if PROCESS_DATA:\n",
    "    # GET TEST COLUMN NAMES\n",
    "    test = cudf.read_csv(os.path.join(DATA_DIR, 'raw', 'test_data.csv'), nrows=1)\n",
    "    T_COLS = test.columns\n",
    "    print(f'There are {len(T_COLS)} test dataframe columns')\n",
    "    \n",
    "    test = pd.read_csv(os.path.join(DATA_DIR, 'raw', 'test_data.csv'), usecols=['customer_ID'])\n",
    "    test['customer_ID'] = test['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "    customers = test.drop_duplicates().sort_index().values.flatten()\n",
    "    print(f'There are {len(customers)} unique customers in test.')\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    # CALCULATE SIZE OF EACH SEPARATE FILE\n",
    "    rows = get_rows(customers, test, NUM_FILES = NUM_FILES_TEST, verbose = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ccd32-b036-4ff4-94f1-c66bd69f43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROCESS_DATA:\n",
    "    # SAVE TEST CUSTOMERS INDEX\n",
    "    test_customer_hashes = cupy.array([],dtype='int64')\n",
    "    \n",
    "    # CREATE PROCESSED TEST FILES AND SAVE TO DISK\n",
    "    for k in range(NUM_FILES_TEST):\n",
    "\n",
    "        # READ CHUNK OF TEST CSV FILE\n",
    "        skip = int(np.sum( rows[:k] ) + 1) #the plus one is for skipping header\n",
    "        df = cudf.read_csv(os.path.join(DATA_DIR, 'raw', 'test_data.csv'), nrows=rows[k], \n",
    "                              skiprows=skip, header=None, names=T_COLS)\n",
    "\n",
    "        # FEATURE ENGINEER DATAFRAME\n",
    "        \n",
    "        # extract the Y, M and D from the date column\n",
    "        df.S_2 = cudf.to_datetime(df.S_2)\n",
    "        df['year'] = (df.S_2.dt.year-2000).astype('int8')\n",
    "        df['month'] = (df.S_2.dt.month).astype('int8')\n",
    "        df['day'] = (df.S_2.dt.day).astype('int8')\n",
    "        del df['S_2']\n",
    "        \n",
    "        if PAD_CUSTOMER_TO_13_ROWS:\n",
    "            tmp = df[['customer_ID']].groupby('customer_ID').customer_ID.agg('count')\n",
    "            more = cupy.array([], dtype='int64') \n",
    "            for j in range(1, 13):\n",
    "                i = tmp.loc[tmp == j].index.values\n",
    "                more = cupy.concatenate([more, cupy.repeat(i, 13-j)])\n",
    "            df_pad = df.iloc[:len(more)].copy().fillna(0)\n",
    "            df_pad = df_pad * 0 - 3 #pad numerical columns with -3\n",
    "            df_pad[CATS] = (df_pad[CATS] * 0 - 2).astype('int8') #pad categorical columns with -2\n",
    "            df_pad['customer_ID'] = more\n",
    "            df = cudf.concat([df, df_pad], axis = 0, ignore_index=True)\n",
    "\n",
    "            del tmp, df_pad\n",
    "            gc.collect()\n",
    "            \n",
    "        # sort by customer ID, then by data. Then rearrange columns with 11 cats first\n",
    "        df = df.sort_values(['customer_ID', 'year', 'month', 'day']).reset_index(drop = True)\n",
    "        df = df.drop(['year', 'month', 'day'], axis=1)\n",
    "\n",
    "        COLS = list(df.columns[1:])\n",
    "        COLS = ['customer_ID'] + CATS + [c for c in COLS if c not in CATS]\n",
    "        df = df[COLS]\n",
    "        \n",
    "        # SAVE TEST CUSTOMERS INDEX\n",
    "        cust = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
    "        test_customer_hashes = cupy.concatenate([test_customer_hashes,cust])\n",
    "\n",
    "        # SAVE FILES\n",
    "        print(f'Test_File_{k+1} has {test.customer_ID.nunique()} customers and shape',test.shape)\n",
    "        data = test.iloc[:,1:].values.reshape((-1,13,188))\n",
    "        cupy.save(f'{PATH_TO_DATA}test_data_{k+1}',data.astype('float32'))\n",
    "        \n",
    "    # SAVE CUSTOMER INDEX OF ALL TEST FILES\n",
    "    cupy.save(f'{PATH_TO_DATA}test_hashes_data', test_customer_hashes)\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del test, data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197e4ef-069b-4129-9e4b-e477d56bdf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152ef1b-410b-40f9-9031-d8b554f9c946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88040cfa-5340-4cff-99f7-8eae238bd150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc32e796-f264-4133-9196-f0f6dc327f49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Some EDA on the data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c91e63-fac2-48f9-8a97-50a968d216aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(DATA_DIR, 'derived', 'processed-splits', 'train-data_0.npy'))\n",
    "y_train = pd.read_parquet(os.path.join(DATA_DIR, 'derived', 'processed-splits', 'train-targets_0.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559ce2e5-c271-432a-a0ea-c635256510a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45891, 13, 188), (45891, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3deae1ac-36ae-438f-acf5-c1a073500e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9fe2d39-91be-4b5c-9502-77f7adb2f7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable B_30 proportion of missing values: 0.0000\n",
      "Variable B_38 proportion of missing values: 0.0000\n",
      "Variable D_114 proportion of missing values: 0.0000\n",
      "Variable D_116 proportion of missing values: 0.0000\n",
      "Variable D_117 proportion of missing values: 0.0000\n",
      "Variable D_120 proportion of missing values: 0.0000\n",
      "Variable D_126 proportion of missing values: 0.0000\n",
      "Variable D_66 proportion of missing values: 0.0000\n",
      "Variable D_68 proportion of missing values: 0.0000\n",
      "Variable D_63 proportion of missing values: 0.0000\n",
      "Variable D_64 proportion of missing values: 0.0000\n",
      "Variable P_2 proportion of missing values: 0.0082\n",
      "Variable D_39 proportion of missing values: 0.0000\n",
      "Variable B_1 proportion of missing values: 0.0000\n",
      "Variable B_2 proportion of missing values: 0.0004\n",
      "Variable R_1 proportion of missing values: 0.0000\n",
      "Variable S_3 proportion of missing values: 0.1561\n",
      "Variable D_41 proportion of missing values: 0.0004\n",
      "Variable B_3 proportion of missing values: 0.0004\n",
      "Variable D_42 proportion of missing values: 0.7163\n",
      "Variable D_43 proportion of missing values: 0.2603\n",
      "Variable D_44 proportion of missing values: 0.0000\n",
      "Variable B_4 proportion of missing values: 0.0000\n",
      "Variable D_45 proportion of missing values: 0.0004\n",
      "Variable B_5 proportion of missing values: 0.0000\n",
      "Variable R_2 proportion of missing values: 0.0000\n",
      "Variable D_46 proportion of missing values: 0.1964\n",
      "Variable D_47 proportion of missing values: 0.0000\n",
      "Variable D_48 proportion of missing values: 0.1176\n",
      "Variable D_49 proportion of missing values: 0.0000\n",
      "Variable B_6 proportion of missing values: 0.0000\n",
      "Variable B_7 proportion of missing values: 0.0000\n",
      "Variable B_8 proportion of missing values: 0.0027\n",
      "Variable D_50 proportion of missing values: 0.4703\n",
      "Variable D_51 proportion of missing values: 0.0000\n",
      "Variable B_9 proportion of missing values: 0.0000\n",
      "Variable R_3 proportion of missing values: 0.0000\n",
      "Variable D_52 proportion of missing values: 0.0097\n",
      "Variable P_3 proportion of missing values: 0.0514\n",
      "Variable B_10 proportion of missing values: 0.0000\n",
      "Variable D_53 proportion of missing values: 0.6399\n",
      "Variable S_5 proportion of missing values: 0.0000\n",
      "Variable B_11 proportion of missing values: 0.0000\n",
      "Variable S_6 proportion of missing values: 0.0000\n",
      "Variable D_54 proportion of missing values: 0.0004\n",
      "Variable R_4 proportion of missing values: 0.0000\n",
      "Variable S_7 proportion of missing values: 0.1561\n",
      "Variable B_12 proportion of missing values: 0.0000\n",
      "Variable S_8 proportion of missing values: 0.0000\n",
      "Variable D_55 proportion of missing values: 0.0598\n",
      "Variable D_56 proportion of missing values: 0.4770\n",
      "Variable B_13 proportion of missing values: 0.0137\n",
      "Variable R_5 proportion of missing values: 0.0000\n",
      "Variable D_58 proportion of missing values: 0.0000\n",
      "Variable S_9 proportion of missing values: 0.4526\n",
      "Variable B_14 proportion of missing values: 0.0000\n",
      "Variable D_59 proportion of missing values: 0.0000\n",
      "Variable D_60 proportion of missing values: 0.0000\n",
      "Variable D_61 proportion of missing values: 0.0920\n",
      "Variable B_15 proportion of missing values: 0.0000\n",
      "Variable S_11 proportion of missing values: 0.0000\n",
      "Variable D_62 proportion of missing values: 0.1209\n",
      "Variable D_65 proportion of missing values: 0.0000\n",
      "Variable B_16 proportion of missing values: 0.0000\n",
      "Variable B_17 proportion of missing values: 0.5061\n",
      "Variable B_18 proportion of missing values: 0.0000\n",
      "Variable B_19 proportion of missing values: 0.0000\n",
      "Variable B_20 proportion of missing values: 0.0000\n",
      "Variable S_12 proportion of missing values: 0.0000\n",
      "Variable R_6 proportion of missing values: 0.0000\n",
      "Variable S_13 proportion of missing values: 0.0000\n",
      "Variable B_21 proportion of missing values: 0.0000\n",
      "Variable D_69 proportion of missing values: 0.0521\n",
      "Variable B_22 proportion of missing values: 0.0000\n",
      "Variable D_70 proportion of missing values: 0.0000\n",
      "Variable D_71 proportion of missing values: 0.0000\n",
      "Variable D_72 proportion of missing values: 0.0000\n",
      "Variable S_15 proportion of missing values: 0.0000\n",
      "Variable B_23 proportion of missing values: 0.0000\n",
      "Variable D_73 proportion of missing values: 0.8330\n",
      "Variable P_4 proportion of missing values: 0.0000\n",
      "Variable D_74 proportion of missing values: 0.0000\n",
      "Variable D_75 proportion of missing values: 0.0000\n",
      "Variable D_76 proportion of missing values: 0.7404\n",
      "Variable B_24 proportion of missing values: 0.0000\n",
      "Variable R_7 proportion of missing values: 0.0000\n",
      "Variable D_77 proportion of missing values: 0.3717\n",
      "Variable B_25 proportion of missing values: 0.0000\n",
      "Variable B_26 proportion of missing values: 0.0004\n",
      "Variable D_78 proportion of missing values: 0.0000\n",
      "Variable D_79 proportion of missing values: 0.0000\n",
      "Variable R_8 proportion of missing values: 0.0000\n",
      "Variable R_9 proportion of missing values: 0.0000\n",
      "Variable S_16 proportion of missing values: 0.0000\n",
      "Variable D_80 proportion of missing values: 0.0000\n",
      "Variable R_10 proportion of missing values: 0.0000\n",
      "Variable R_11 proportion of missing values: 0.0000\n",
      "Variable B_27 proportion of missing values: 0.0004\n",
      "Variable D_81 proportion of missing values: 0.0000\n",
      "Variable D_82 proportion of missing values: 0.0000\n",
      "Variable S_17 proportion of missing values: 0.0000\n",
      "Variable R_12 proportion of missing values: 0.0000\n",
      "Variable B_28 proportion of missing values: 0.0000\n",
      "Variable R_13 proportion of missing values: 0.0000\n",
      "Variable D_83 proportion of missing values: 0.0000\n",
      "Variable R_14 proportion of missing values: 0.0000\n",
      "Variable R_15 proportion of missing values: 0.0000\n",
      "Variable D_84 proportion of missing values: 0.0000\n",
      "Variable R_16 proportion of missing values: 0.0000\n",
      "Variable B_29 proportion of missing values: 0.7837\n",
      "Variable S_18 proportion of missing values: 0.0000\n",
      "Variable D_86 proportion of missing values: 0.0000\n",
      "Variable D_87 proportion of missing values: 0.0000\n",
      "Variable R_17 proportion of missing values: 0.0000\n",
      "Variable R_18 proportion of missing values: 0.0000\n",
      "Variable D_88 proportion of missing values: 0.8386\n",
      "Variable B_31 proportion of missing values: 0.0000\n",
      "Variable S_19 proportion of missing values: 0.0000\n",
      "Variable R_19 proportion of missing values: 0.0000\n",
      "Variable B_32 proportion of missing values: 0.0000\n",
      "Variable S_20 proportion of missing values: 0.0000\n",
      "Variable R_20 proportion of missing values: 0.0000\n",
      "Variable R_21 proportion of missing values: 0.0000\n",
      "Variable B_33 proportion of missing values: 0.0000\n",
      "Variable D_89 proportion of missing values: 0.0000\n",
      "Variable R_22 proportion of missing values: 0.0000\n",
      "Variable R_23 proportion of missing values: 0.0000\n",
      "Variable D_91 proportion of missing values: 0.0000\n",
      "Variable D_92 proportion of missing values: 0.0000\n",
      "Variable D_93 proportion of missing values: 0.0000\n",
      "Variable D_94 proportion of missing values: 0.0000\n",
      "Variable R_24 proportion of missing values: 0.0000\n",
      "Variable R_25 proportion of missing values: 0.0000\n",
      "Variable D_96 proportion of missing values: 0.0000\n",
      "Variable S_22 proportion of missing values: 0.0022\n",
      "Variable S_23 proportion of missing values: 0.0000\n",
      "Variable S_24 proportion of missing values: 0.0022\n",
      "Variable S_25 proportion of missing values: 0.0018\n",
      "Variable S_26 proportion of missing values: 0.0000\n",
      "Variable D_102 proportion of missing values: 0.0137\n",
      "Variable D_103 proportion of missing values: 0.0000\n",
      "Variable D_104 proportion of missing values: 0.0166\n",
      "Variable D_105 proportion of missing values: 0.4651\n",
      "Variable D_106 proportion of missing values: 0.0000\n",
      "Variable D_107 proportion of missing values: 0.0000\n",
      "Variable B_36 proportion of missing values: 0.0000\n",
      "Variable B_37 proportion of missing values: 0.0000\n",
      "Variable R_26 proportion of missing values: 0.0000\n",
      "Variable R_27 proportion of missing values: 0.0098\n",
      "Variable D_108 proportion of missing values: 0.0000\n",
      "Variable D_109 proportion of missing values: 0.0000\n",
      "Variable D_110 proportion of missing values: 0.8370\n",
      "Variable D_111 proportion of missing values: 0.0000\n",
      "Variable B_39 proportion of missing values: 0.8370\n",
      "Variable D_112 proportion of missing values: 0.0004\n",
      "Variable B_40 proportion of missing values: 0.0000\n",
      "Variable S_27 proportion of missing values: 0.2158\n",
      "Variable D_113 proportion of missing values: 0.0000\n",
      "Variable D_115 proportion of missing values: 0.0309\n",
      "Variable D_118 proportion of missing values: 0.0309\n",
      "Variable D_119 proportion of missing values: 0.0309\n",
      "Variable D_121 proportion of missing values: 0.0309\n",
      "Variable D_122 proportion of missing values: 0.0000\n",
      "Variable D_123 proportion of missing values: 0.0000\n",
      "Variable D_124 proportion of missing values: 0.0000\n",
      "Variable D_125 proportion of missing values: 0.0000\n",
      "Variable D_127 proportion of missing values: 0.0000\n",
      "Variable D_128 proportion of missing values: 0.0166\n",
      "Variable D_129 proportion of missing values: 0.0000\n",
      "Variable B_41 proportion of missing values: 0.0000\n",
      "Variable B_42 proportion of missing values: 0.8275\n",
      "Variable D_130 proportion of missing values: 0.0166\n",
      "Variable D_131 proportion of missing values: 0.0166\n",
      "Variable D_132 proportion of missing values: 0.7663\n",
      "Variable D_133 proportion of missing values: 0.0141\n",
      "Variable R_28 proportion of missing values: 0.0000\n",
      "Variable D_134 proportion of missing values: 0.8134\n",
      "Variable D_135 proportion of missing values: 0.0000\n",
      "Variable D_136 proportion of missing values: 0.0000\n",
      "Variable D_137 proportion of missing values: 0.0000\n",
      "Variable D_138 proportion of missing values: 0.0000\n",
      "Variable D_139 proportion of missing values: 0.0000\n",
      "Variable D_140 proportion of missing values: 0.0000\n",
      "Variable D_141 proportion of missing values: 0.0166\n",
      "Variable D_142 proportion of missing values: 0.6972\n",
      "Variable D_143 proportion of missing values: 0.0000\n",
      "Variable D_144 proportion of missing values: 0.0137\n",
      "Variable D_145 proportion of missing values: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(188):\n",
    "    print(f\"Variable {COLS[i]} proportion of missing values: {X_train[X_train[:, 0, i] == -0.5].shape[0] / X_train.shape[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d4e9aa-c248-4f11-be53-a05934d8a00e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45891, 13, 188)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d353c9-90f7-4925-b72b-5d2b32e6e1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc34f28-e13c-4822-8299-395d3856a8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train == -4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b50ea-082e-41c0-b749-386aeaeb325b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f03e609-e82a-4041-a893-785adbb32cee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the data for PyTorch and setting up testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82701366-d7db-4a7c-94aa-be85943e1a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPETITION METRIC FROM Konstantin Yakovlev\n",
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86de8900-99d3-4c48-952f-5f0b9b840fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_numpy_data(val_idx : list, fill_dict, corrupt_func = None, preprocess_obj = None, **data_loader_kwargs) -> (torch.utils.data.DataLoader, torch.utils.data.DataLoader):\n",
    "    \"\"\"\n",
    "    val_idx is a list of integers denoting which of the [0, 1, ..., NUM_SPLITS-1] splits to use\n",
    "    as validation data, and the rest will be used as training data\n",
    "    \n",
    "    if num_cat_columns is set to an integer, the first num_cat_columns columns will have their values shifted to all be non-negative,\n",
    "    as these are categorical integer indices.\n",
    "    \n",
    "    The fill dict should contain the following keys:\n",
    "    * nan\n",
    "    * pad_categorical\n",
    "    * pad_numeric\n",
    "    \"\"\"\n",
    "    split_data_dir = os.path.join(DATA_DIR, \"derived\", \"processed-splits\")\n",
    "    \n",
    "    def load_aux(idx : list, is_train : bool):\n",
    "        Xs = []; ys = []\n",
    "        for k in val_idx:\n",
    "            Xs.append(np.load(os.path.join(split_data_dir, f\"train-data_{k}.npy\")))\n",
    "            ys.append(pd.read_parquet(os.path.join(split_data_dir, f\"train-targets_{k}.parquet\")))\n",
    "        \n",
    "        Xs = np.concatenate(Xs, axis = 0)\n",
    "        ys = pd.concat(ys).target.values\n",
    "        \n",
    "        # fill NAs and padded values with provided numerics\n",
    "        # (See PAD_CUSTOMER_TO_13_ROWS code)\n",
    "        na_mask = (Xs == -0.5)\n",
    "        pad_cat_mask = (Xs == -2)\n",
    "        pad_numeric_mask = (Xs == -3)\n",
    "        \n",
    "        Xs[na_mask] = fill_dict['nan']\n",
    "        Xs[pad_cat_mask] = fill_dict['pad_categorical']\n",
    "        Xs[pad_numeric_mask] = fill_dict['pad_numeric']\n",
    "        \n",
    "        # make sure all the categorical entries are non-negative for the embedding layer to work correctly\n",
    "        if NUM_CATEGORICAL_COLUMNS is not None:\n",
    "            Xs[:, :, :NUM_CATEGORICAL_COLUMNS] = Xs[:, :, :NUM_CATEGORICAL_COLUMNS] - np.amin(Xs[:, :, :NUM_CATEGORICAL_COLUMNS], axis = 0, keepdims = True)\n",
    "\n",
    "        # corrupt the data with specified function (only do this on the non-categorical variables)\n",
    "        if corrupt_func is not None:\n",
    "            Xs[:, :, NUM_CATEGORICAL_COLUMNS:], y = corrupt_func(Xs[:, :, NUM_CATEGORICAL_COLUMNS:], ys)\n",
    "        \n",
    "        # the transformation is only applied to the numeric columns\n",
    "        if is_train and preprocess_obj is not None:\n",
    "            Xs[:, :, NUM_CATEGORICAL_COLUMNS:] = preprocess_obj.fit_transform(Xs[:, :, NUM_CATEGORICAL_COLUMNS:], ys)\n",
    "        elif preprocess_obj is not None:\n",
    "            Xs[:, :, NUM_CATEGORICAL_COLUMNS:] = preprocess_obj.transform(Xs[:, :, NUM_CATEGORICAL_COLUMNS:])\n",
    "        \n",
    "        # compile the DataLoader object and return\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset = torch.utils.data.TensorDataset(\n",
    "                torch.from_numpy(Xs).type(torch.float32),\n",
    "                torch.from_numpy(ys).type(torch.float32)\n",
    "            ), **data_loader_kwargs)\n",
    "        \n",
    "        return data_loader\n",
    "    \n",
    "    train_idx = [i for i in list(range(NUM_SPLITS)) if i not in val_idx]\n",
    "    train_loader = load_aux(train_idx, is_train = True)\n",
    "    val_loader = load_aux(val_idx, is_train = False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "785299ae-5f0b-4362-babf-95152bdd371a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loader, val_loader = load_numpy_data([8, 9], fill_dict = fill_dict, corrupt_func=identity_corrupt, preprocess_obj=IdentityTransform(), batch_size = 1024, drop_last = True, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6f282bc4-1d70-4ae8-be65-a590045309dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 13, 188]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "# for x, y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26c497ef-cf51-4fb0-a2a8-4915ea7ae27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, training_loader, optimizer, epoch_number):\n",
    "    running_loss = 0.\n",
    "    running_metric = 0.\n",
    "    # last_loss = 0.\n",
    "    # last_metric = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(DEV), labels.to(DEV)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        running_metric += amex_metric_mod(labels.detach().cpu().numpy(), outputs.detach().cpu().numpy())\n",
    "\n",
    "    last_loss = running_loss / (i + 1) # loss per batch\n",
    "    last_metric = running_metric / (i + 1) # metric per batch\n",
    "    # print('  batch {} loss: {} metric: {}'.format(i + 1, last_loss, last_metric))\n",
    "    # tb_x = epoch_index * len(training_loader) + i + 1\n",
    "    # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "\n",
    "    return last_loss, last_metric\n",
    "\n",
    "\n",
    "def fit_model(model, loss_fn, train_loader, val_loader, optimizer, num_epochs, verbose = True):\n",
    "    best_vloss = 1_000_000.\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    history = {\n",
    "        \"timestamp\" : timestamp,\n",
    "        \"train_loss\" : [],\n",
    "        \"val_loss\" : [],\n",
    "        \"train_amex_metric\" : [],\n",
    "        \"val_amex_metric\" : [],\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(total = num_epochs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss, avg_metric = train_one_epoch(model, loss_fn, train_loader, optimizer, epoch + 1)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        running_vmetric = 0.0\n",
    "        # Set the model to evaluation mode, disabling dropout and using population\n",
    "        # statistics for batch normalization.\n",
    "        model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                vinputs, vlabels = vinputs.to(DEV), vlabels.to(DEV)\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels).cpu().item()\n",
    "                vmetric = amex_metric_mod(vlabels.cpu().numpy(), voutputs.cpu().numpy())\n",
    "                running_vloss += vloss\n",
    "                running_vmetric += vmetric\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        avg_vmetric = running_vmetric / (i + 1)\n",
    "        if verbose:\n",
    "            print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "            print('AMEX metric train {} valid {}'.format(avg_metric, avg_vmetric))\n",
    "            \n",
    "        # update progress bar\n",
    "        pbar.update()\n",
    "        pbar.set_description(\"LOSS train {:.4f} valid {:.4f}. AMEX METRIC train {:.4f} valid {:.4f}\".format(avg_loss, avg_vloss, avg_metric, avg_vmetric))\n",
    "            \n",
    "        # Log the metric values\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        history['train_amex_metric'].append(avg_metric)\n",
    "        history['val_loss'].append(avg_vloss)\n",
    "        history['val_amex_metric'].append(avg_vmetric)\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        # writer.add_scalars('Training vs. Validation Loss',\n",
    "        #                 { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "        #                 epoch_number + 1)\n",
    "        # writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        # if avg_vloss < best_vloss:\n",
    "        #     best_vloss = avg_vloss\n",
    "        #     model_path = 'model_{}_{}'.format(timestamp, epoch)\n",
    "        #     torch.save(model.state_dict(), model_path)\n",
    "    pbar.refresh()\n",
    "    \n",
    "    return history\n",
    "\n",
    "def cross_validate_model(model : nn.Module, loss_fn, data_loader_kwargs, fit_kwargs, fill_dict, corrupt_func, preprocess_init_fn,\n",
    "                         folds = [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    \n",
    "    history_metrics = {\n",
    "        \"train_loss\"        : np.zeros((fit_kwargs['num_epochs'], len(folds))),\n",
    "        \"val_loss\"          : np.zeros((fit_kwargs['num_epochs'], len(folds))),\n",
    "        \"train_amex_metric\" : np.zeros((fit_kwargs['num_epochs'], len(folds))),\n",
    "        \"val_amex_metric\"   : np.zeros((fit_kwargs['num_epochs'], len(folds))),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i, val_idx in tqdm(enumerate(folds), desc = \"Cross-validating model\", total = len(folds)):\n",
    "        # we want to train the model from scratch\n",
    "        reset_all_weights(model)\n",
    "        \n",
    "        train_loader, val_loader = load_numpy_data(val_idx, fill_dict, corrupt_func, preprocess_init_fn(), **data_loader_kwargs)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = fit_kwargs['learning_rate'])\n",
    "        \n",
    "        history = fit_model(model, loss_fn, train_loader, val_loader, optimizer, fit_kwargs['num_epochs'], fit_kwargs['verbose'])\n",
    "        \n",
    "        # save the various metrics recorded\n",
    "        for history_key in history_metrics.keys():\n",
    "            history_metrics[history_key][:, i] = np.array(history[history_key])\n",
    "        \n",
    "    hist_keys = list(history_metrics.keys())\n",
    "    for history_key in hist_keys:\n",
    "        # compute the mean and std of the final value, reducing over folds\n",
    "        history_metrics[f\"{history_key}_mean\"] = np.mean(history_metrics[history_key][-1, :])\n",
    "        history_metrics[f\"{history_key}_sd\"] = np.std(history_metrics[history_key][-1, :])\n",
    "    \n",
    "    return history_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d09ee1-6487-4127-a270-70d6cd1c989c",
   "metadata": {},
   "source": [
    "We now define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac000b74-e5f0-44ac-91a1-99c545fabffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_all_weights(model: nn.Module) -> None:\n",
    "    \"\"\"\n",
    "    refs:\n",
    "        - https://discuss.pytorch.org/t/how-to-re-set-alll-parameters-in-a-network/20819/6\n",
    "        - https://stackoverflow.com/questions/63627997/reset-parameters-of-a-neural-network-in-pytorch\n",
    "        - https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "    \"\"\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        # - check if the current module has reset_parameters & if it's callabed called it on m\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "\n",
    "    # Applies fn recursively to every submodule see: https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "    model.apply(fn=weight_reset)\n",
    "\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, layer_dim, emb_dim, num_cat_columns = 11, dropout_prob = 0.2):\n",
    "        super(GRUNet, self).__init__()\n",
    "        \n",
    "        # save the params\n",
    "        self.layer_dim = layer_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_cat_columns = num_cat_columns\n",
    "        \n",
    "        # the layers we need\n",
    "        emb_layers = []\n",
    "        for k in range(num_cat_columns):\n",
    "            emb_layers.append(nn.Embedding(10, emb_dim))\n",
    "        self.emb_layers = nn.ModuleList(emb_layers)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size = num_features - num_cat_columns + num_cat_columns * emb_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = layer_dim,\n",
    "            batch_first = True,\n",
    "            dropout = dropout_prob\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First 11 columns are categorical, next 177 are numerical\n",
    "        embedding_outs = []\n",
    "        for k in range(self.num_cat_columns):\n",
    "            emb = self.emb_layers[k]\n",
    "            col = x[:, :, k].type(torch.int32)\n",
    "            embedding_outs.append(emb(col))\n",
    "        \n",
    "        x = torch.concat([x[:, :, self.num_cat_columns:]] + embedding_outs, dim = -1)\n",
    "        \n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim, device = DEV).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, _ = self.gru(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.relu1(self.fc1(out))\n",
    "        out = self.relu2(self.fc2(out))\n",
    "        out = self.sigmoid(self.fc3(out))\n",
    "        \n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4035e5-1619-42b4-a885-9fa5596c43de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiments\n",
    "\n",
    "Below starts setting hyperparameters and experimentation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ea983f-aec1-420d-ad46-6ae4b118b2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identity_corrupt(X, y) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    X of shape (num_examples, series_length, num_features)\n",
    "    \"\"\"\n",
    "    return X, y\n",
    "\n",
    "# Note this should follow the interface of sklearn BaseEstimator using a fit, transform and fit_transform function\n",
    "class IdentityTransform(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        # https://docs.cupy.dev/en/stable/user_guide/interoperability.html#pytorch\n",
    "        # consider using cupy if too slow with base numpy ^^\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "data_loader_kwargs = {\n",
    "    'batch_size' : 1024,\n",
    "    'shuffle' : True,\n",
    "    'drop_last' : False,\n",
    "}\n",
    "fit_kwargs = {\n",
    "    'learning_rate' : 0.001,\n",
    "    'num_epochs' : 8,\n",
    "    'verbose' : False,\n",
    "}\n",
    "\n",
    "fill_dict = {\n",
    "    'nan' : -0.5,\n",
    "    'pad_categorical' : -2,\n",
    "    'pad_numeric' : -1.,\n",
    "}\n",
    "\n",
    "model = GRUNet(188, 128, 2, 4).to(DEV)\n",
    "loss_fn = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52bbf843-6af0-4c15-b9f8-252ef2662570",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb235b7875846ea9ab3e76ae536c2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross-validating model:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a807313d05834785928a588d9735da8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236071ff06844a30b04c36b25b3f37bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e928e3e3d295491aad0a2e0d532b8014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce425da058b4f4bbdfbf493cddf9102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1978691bc284b9bb9aee25c7a7b12c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = cross_validate_model(model, loss_fn, data_loader_kwargs, fit_kwargs, fill_dict, identity_corrupt, lambda: IdentityTransform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8d811ed-f9d7-4f24-9801-2d4a642d43d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2303 +- 0.0057\n",
      "Validation competition metric: 0.7811 +- 0.0086\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation loss: {history['val_loss_mean']:.4f} +- {1.96 * history['val_loss_sd']:.4f}\")\n",
    "print(f\"Validation competition metric: {history['val_amex_metric_mean']:.4f} +- {1.96 * history['val_amex_metric_sd']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb2a9c43-05d4-4408-a622-e334f1f0165b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b8c70787a64c8987d3491c5c749bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross-validating model:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed057556c67494aac8f6c9b520fece0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a45161aa404accb01123553184d640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa56ab4af2c040399562b23a95b3f65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e443176bcf94a7bbf998e84d47372cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827070c0fb0446ec8cd8cbe65c207832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now test standard scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class StandardScalerTimeSeries(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator):\n",
    "    def __init__(self, time_series_length : int):\n",
    "        self.ss = preprocessing.StandardScaler()\n",
    "        self.T = time_series_length\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        X = X.reshape((X.shape[0], -1))\n",
    "        self.ss.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.reshape((X.shape[0], -1))\n",
    "        X = self.ss.transform(X)\n",
    "        X = X.reshape((X.shape[0], self.T, -1))\n",
    "        return X\n",
    "\n",
    "history = cross_validate_model(model, loss_fn, data_loader_kwargs, fit_kwargs, fill_dict, identity_corrupt, lambda : StandardScalerTimeSeries(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24eba346-e401-40b9-900c-05274cff5c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1926 +- 0.0084\n",
      "Validation competition metric: 0.8381 +- 0.0111\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation loss: {history['val_loss_mean']:.4f} +- {1.96 * history['val_loss_sd']:.4f}\")\n",
    "print(f\"Validation competition metric: {history['val_amex_metric_mean']:.4f} +- {1.96 * history['val_amex_metric_sd']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8374079-92d0-4fe2-9b8e-9da850cb9a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc2ee80-1d78-483b-81e2-61c84dd9a27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80994761bf4d4fac83692f6b37ca25fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43b418-0b10-4f9f-b0fd-bfbbc89529e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28ce57-1ee0-48a7-89c2-070b316c7193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de1c1f13-013c-408e-93ef-56fd87996d5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7683b8cc-d943-4d8a-827e-396e438de637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-7948374999843709812</th>\n",
       "      <td>0.456345</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>1.004786</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.104417205</td>\n",
       "      <td>0.055832</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.1532619</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8645856538965131241</th>\n",
       "      <td>0.756145</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.721992</td>\n",
       "      <td>0.293841</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.597289562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012906</td>\n",
       "      <td>0.020493843</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8791650985376527784</th>\n",
       "      <td>0.902983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>1.006431</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>-0.04807209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8454268923601939076</th>\n",
       "      <td>0.823955</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.029923</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.080841521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.01998057</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7657899299564496661</th>\n",
       "      <td>0.704843</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>0.939805</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.090517749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.023059726</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.862662</td>\n",
       "      <td>0.057864944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8713127797801704272</th>\n",
       "      <td>0.485146</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.458467</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>0.172573</td>\n",
       "      <td>0.283588727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549716</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.019031034</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7807490439052895278</th>\n",
       "      <td>0.815616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.814304</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.413618008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.01740142</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985106</td>\n",
       "      <td>0.573939919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760147</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8686894840230819858</th>\n",
       "      <td>0.385107</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.024687</td>\n",
       "      <td>1.006793</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.136240949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.058567395</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8354179577782462610</th>\n",
       "      <td>0.871444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046527</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.17705514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8931489125857784903</th>\n",
       "      <td>0.399897</td>\n",
       "      <td>58.666667</td>\n",
       "      <td>0.057268</td>\n",
       "      <td>0.670835</td>\n",
       "      <td>0.170688</td>\n",
       "      <td>0.70744276</td>\n",
       "      <td>0.729519</td>\n",
       "      <td>0.048065</td>\n",
       "      <td>0.871447563</td>\n",
       "      <td>0.68723774</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45891 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           P_2       D_39       B_1       B_2       R_1  \\\n",
       "customer_ID                                                               \n",
       "-7948374999843709812  0.456345   5.000000  0.026282  1.004786  0.005375   \n",
       "-8645856538965131241  0.756145   6.000000  0.721992  0.293841  0.006862   \n",
       "-8791650985376527784  0.902983   0.000000  0.015144  1.006431  0.005585   \n",
       "-8454268923601939076  0.823955  10.000000  0.029923  1.006844  0.002948   \n",
       "-7657899299564496661  0.704843   8.666667  0.010633  0.939805  0.006357   \n",
       "...                        ...        ...       ...       ...       ...   \n",
       "-8713127797801704272  0.485146   6.333333  0.458467  0.024092  0.172573   \n",
       "-7807490439052895278  0.815616   0.000000  0.004466  0.814304  0.004319   \n",
       "-8686894840230819858  0.385107   7.000000  0.024687  1.006793  0.003685   \n",
       "-8354179577782462610  0.871444   1.000000  0.046527  0.148453  0.005374   \n",
       "-8931489125857784903  0.399897  58.666667  0.057268  0.670835  0.170688   \n",
       "\n",
       "                              S_3      D_41       B_3         D_42  \\\n",
       "customer_ID                                                          \n",
       "-7948374999843709812  0.104417205  0.055832  0.008278         <NA>   \n",
       "-8645856538965131241  0.597289562  0.000000  0.012906  0.020493843   \n",
       "-8791650985376527784  -0.04807209  0.000000  0.005553         <NA>   \n",
       "-8454268923601939076  0.080841521  0.000000  0.009003         <NA>   \n",
       "-7657899299564496661  0.090517749  0.000000  0.010066  0.023059726   \n",
       "...                           ...       ...       ...          ...   \n",
       "-8713127797801704272  0.283588727  0.000000  0.549716         <NA>   \n",
       "-7807490439052895278  0.413618008  0.000000  0.005084         <NA>   \n",
       "-8686894840230819858  0.136240949  0.000000  0.005758         <NA>   \n",
       "-8354179577782462610   0.17705514  0.000000  0.120511         <NA>   \n",
       "-8931489125857784903   0.70744276  0.729519  0.048065  0.871447563   \n",
       "\n",
       "                             D_43  ...  D_137  D_138     D_139  D_140  \\\n",
       "customer_ID                        ...                                  \n",
       "-7948374999843709812    0.1532619  ...   -1.0   -1.0  0.000000    0.0   \n",
       "-8645856538965131241         <NA>  ...   -1.0   -1.0 -0.333333    0.0   \n",
       "-8791650985376527784         <NA>  ...   -1.0   -1.0  0.000000    0.0   \n",
       "-8454268923601939076   0.01998057  ...   -1.0   -1.0  0.000000    0.0   \n",
       "-7657899299564496661         <NA>  ...   -1.0   -1.0  1.000000    0.0   \n",
       "...                           ...  ...    ...    ...       ...    ...   \n",
       "-8713127797801704272  0.019031034  ...   -1.0   -1.0  0.000000    0.0   \n",
       "-7807490439052895278   0.01740142  ...   -1.0   -1.0  1.000000    0.0   \n",
       "-8686894840230819858  0.058567395  ...   -1.0   -1.0  0.000000    0.0   \n",
       "-8354179577782462610         <NA>  ...   -1.0   -1.0  0.000000    0.0   \n",
       "-8931489125857784903   0.68723774  ...   -1.0   -1.0  0.000000    0.0   \n",
       "\n",
       "                         D_141        D_142     D_143     D_144     D_145  \\\n",
       "customer_ID                                                                 \n",
       "-7948374999843709812  0.000000         <NA>  0.000000  0.006185  0.000000   \n",
       "-8645856538965131241  0.000000         <NA> -0.333333  0.007025 -0.333333   \n",
       "-8791650985376527784  0.000000         <NA>  0.000000  0.004280  0.000000   \n",
       "-8454268923601939076  0.000000         <NA>  0.000000  0.006056  0.000000   \n",
       "-7657899299564496661  0.862662  0.057864944  1.000000  0.007062  4.333333   \n",
       "...                        ...          ...       ...       ...       ...   \n",
       "-8713127797801704272  0.000000         <NA>  0.000000  0.004491  0.000000   \n",
       "-7807490439052895278  0.985106  0.573939919  1.000000  0.760147  2.000000   \n",
       "-8686894840230819858  0.000000         <NA>  0.000000  0.005170  0.000000   \n",
       "-8354179577782462610  0.000000         <NA>  0.000000  0.004699  0.000000   \n",
       "-8931489125857784903  0.000000         <NA>  0.000000  0.003955  0.000000   \n",
       "\n",
       "                      target  \n",
       "customer_ID                   \n",
       "-7948374999843709812     0.0  \n",
       "-8645856538965131241     0.0  \n",
       "-8791650985376527784     0.0  \n",
       "-8454268923601939076     0.0  \n",
       "-7657899299564496661     0.0  \n",
       "...                      ...  \n",
       "-8713127797801704272     0.0  \n",
       "-7807490439052895278     0.0  \n",
       "-8686894840230819858     0.0  \n",
       "-8354179577782462610     0.0  \n",
       "-8931489125857784903     1.0  \n",
       "\n",
       "[45891 rows x 189 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = cudf.read_parquet(os.path.join(dataset_dir, 'derived', 'splits', 'train_0.parquet'))\n",
    "\n",
    "# look at average values for last 3 months\n",
    "df_train = df2.groupby('customer_ID', sort=False).tail(3).groupby('customer_ID').mean()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7664f4-f828-48c9-8342-f2ebfca09dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(df_train.fillna(0.5).iloc[:, :(df_train.shape[1] - 1)].values, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072a1eec-72d0-4611-936b-d946f977ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(df_train.target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e8107a-bad4-42d5-b0d7-cf7b9291e9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExampleNet(\n",
       "  (fc1): Linear(in_features=188, out_features=64, bias=True)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExampleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ExampleNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "mod = ExampleNet()\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27533c9f-dd0d-418c-8709-0476246b7bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_dat = torch.utils.data.DataLoader(torch.hstack((X_train, y_train.unsqueeze(1))), batch_size = 64)\n",
    "optim = torch.optim.Adam(mod.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(train_dat):\n",
    "        inputs, labels = data[:, :-1], data[:, -1]\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.unsqueeze(1).to('cuda')\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        out = mod(inputs)\n",
    "        \n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return running_loss / num_batches\n",
    "\n",
    "# move everything to the GPU\n",
    "mod = mod.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a95fd35-4f0c-4040-898c-d7e8675cdaae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "0.32613843656599023\n",
      "EPOCH 2:\n",
      "0.26247388131210897\n",
      "EPOCH 3:\n",
      "0.2575088815042401\n",
      "EPOCH 4:\n",
      "0.2529879827285834\n",
      "EPOCH 5:\n",
      "0.2500592030268318\n"
     ]
    }
   ],
   "source": [
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    mod.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "    print(avg_loss)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cab164a-c97d-45be-b13a-f18a6b29c0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2fa4e80-4bb9-4061-aaee-2eaad42769e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mod.train(False)\n",
    "\n",
    "y_target_all = None\n",
    "y_pred_all = None\n",
    "\n",
    "for dat in train_dat:\n",
    "    X_train, y_train = dat[:, :-1], dat[:, -1].unsqueeze(1)\n",
    "    X_train = X_train.to('cuda')\n",
    "    y_train = y_train.to('cuda')\n",
    "    \n",
    "    y_pred = torch.sigmoid(mod(X_train))\n",
    "    \n",
    "    if y_target_all is None:\n",
    "        y_target_all = y_train.to('cpu').squeeze(1)\n",
    "        y_pred_all = y_pred.to('cpu').squeeze(1)\n",
    "    else:\n",
    "        y_target_all = torch.hstack([y_target_all, y_train.squeeze(1).to('cpu')])\n",
    "        y_pred_all = torch.hstack([y_pred_all, y_pred.squeeze(1).to('cpu')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b40bc157-e0e6-488b-a56e-e98e0506d417",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7600681393020587"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = pd.DataFrame({'target' : y_target_all.detach().numpy()})\n",
    "y_pred = pd.DataFrame({'prediction' : y_pred_all.detach().numpy()})\n",
    "\n",
    "amex_metric(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e951110-1ebd-48f6-8a0e-6dd300564fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492f450-0f03-4268-8844-bf4320062600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526915d0-502e-48f0-ac47-ca2fa2c0c788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23032a-1329-443c-a56a-18934f88ae45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428bf62-f259-43ce-8651-0df404e379b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e888f25-9e4d-471f-847e-e9fba7d36c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad2ef0-78c2-4286-9e56-e1ce3c699820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f870f58-e516-493d-98c1-2e3745ea9098",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Example preprocessing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700327d7-4fd0-402a-9532-778e470d272f",
   "metadata": {},
   "source": [
    "The below code is taken from the example processing of the training data, by Chris Deotte, on their [TensorFlow GRU Starter](https://www.kaggle.com/code/cdeotte/tensorflow-gru-starter-0-790) kaggle discussion post.\n",
    "\n",
    "TODO: look at the below code and change accordingly...\n",
    "also figure out how to do this withou `cudf`, the improved dataframe library...\n",
    "Consider if need this library later when getting on to the preprocessing methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebe75a-caad-4310-a781-90bf13a165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE SIZE OF EACH SEPARATE FILE\n",
    "def get_rows(customers, train, NUM_FILES = 10, verbose = ''):\n",
    "    chunk = len(customers)//NUM_FILES\n",
    "    if verbose != '':\n",
    "        print(f'We will split {verbose} data into {NUM_FILES} separate files.')\n",
    "        print(f'There will be {chunk} customers in each file (except the last file).')\n",
    "        print('Below are number of rows in each file:')\n",
    "    rows = []\n",
    "\n",
    "    for k in range(NUM_FILES):\n",
    "        if k==NUM_FILES-1: cc = customers[k*chunk:]\n",
    "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
    "        s = train.loc[train.customer_ID.isin(cc)].shape[0]\n",
    "        rows.append(s)\n",
    "    if verbose != '': print( rows )\n",
    "    return rows\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    NUM_FILES = 10\n",
    "    rows = get_rows(customers, train, NUM_FILES = NUM_FILES, verbose = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48ee06-30e0-4dea-9076-a6806868d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(train, PAD_CUSTOMER_TO_13_ROWS = True, targets = None):\n",
    "        \n",
    "    # REDUCE STRING COLUMNS \n",
    "    # from 64 bytes to 8 bytes, and 10 bytes to 3 bytes respectively\n",
    "    train['customer_ID'] = train['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    train.S_2 = cudf.to_datetime( train.S_2 )\n",
    "    train['year'] = (train.S_2.dt.year-2000).astype('int8')\n",
    "    train['month'] = (train.S_2.dt.month).astype('int8')\n",
    "    train['day'] = (train.S_2.dt.day).astype('int8')\n",
    "    del train['S_2']\n",
    "        \n",
    "    # LABEL ENCODE CAT COLUMNS (and reduce to 1 byte)\n",
    "    # with 0: padding, 1: nan, 2,3,4,etc: values\n",
    "    d_63_map = {'CL':2, 'CO':3, 'CR':4, 'XL':5, 'XM':6, 'XZ':7}\n",
    "    train['D_63'] = train.D_63.map(d_63_map).fillna(1).astype('int8')\n",
    "\n",
    "    d_64_map = {'-1':2,'O':3, 'R':4, 'U':5}\n",
    "    train['D_64'] = train.D_64.map(d_64_map).fillna(1).astype('int8')\n",
    "    \n",
    "    CATS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68']\n",
    "    OFFSETS = [2,1,2,2,3,2,3,2,2] #2 minus minimal value in full train csv\n",
    "    # then 0 will be padding, 1 will be NAN, 2,3,4,etc will be values\n",
    "    for c,s in zip(CATS,OFFSETS):\n",
    "        train[c] = train[c] + s\n",
    "        train[c] = train[c].fillna(1).astype('int8')\n",
    "    CATS += ['D_63','D_64']\n",
    "    \n",
    "    # ADD NEW FEATURES HERE\n",
    "    # EXAMPLE: train['feature_189'] = etc etc etc\n",
    "    # EXAMPLE: train['feature_190'] = etc etc etc\n",
    "    # IF CATEGORICAL, THEN ADD TO CATS WITH: CATS += ['feaure_190'] etc etc etc\n",
    "    \n",
    "    # REDUCE MEMORY DTYPE\n",
    "    SKIP = ['customer_ID','year','month','day']\n",
    "    for c in train.columns:\n",
    "        if c in SKIP: continue\n",
    "        if str( train[c].dtype )=='int64':\n",
    "            train[c] = train[c].astype('int32')\n",
    "        if str( train[c].dtype )=='float64':\n",
    "            train[c] = train[c].astype('float32')\n",
    "            \n",
    "    # PAD ROWS SO EACH CUSTOMER HAS 13 ROWS\n",
    "    if PAD_CUSTOMER_TO_13_ROWS:\n",
    "        tmp = train[['customer_ID']].groupby('customer_ID').customer_ID.agg('count')\n",
    "        more = cupy.array([],dtype='int64') \n",
    "        for j in range(1,13):\n",
    "            i = tmp.loc[tmp==j].index.values\n",
    "            more = cupy.concatenate([more,cupy.repeat(i,13-j)])\n",
    "        df = train.iloc[:len(more)].copy().fillna(0)\n",
    "        df = df * 0 - 1 #pad numerical columns with -1\n",
    "        df[CATS] = (df[CATS] * 0).astype('int8') #pad categorical columns with 0\n",
    "        df['customer_ID'] = more\n",
    "        train = cudf.concat([train,df],axis=0,ignore_index=True)\n",
    "        \n",
    "    # ADD TARGETS (and reduce to 1 byte)\n",
    "    if targets is not None:\n",
    "        train = train.merge(targets,on='customer_ID',how='left')\n",
    "        train.target = train.target.astype('int8')\n",
    "        \n",
    "    # FILL NAN\n",
    "    train = train.fillna(-0.5) #this applies to numerical columns\n",
    "    \n",
    "    # SORT BY CUSTOMER THEN DATE\n",
    "    train = train.sort_values(['customer_ID','year','month','day']).reset_index(drop=True)\n",
    "    train = train.drop(['year','month','day'],axis=1)\n",
    "    \n",
    "    # REARRANGE COLUMNS WITH 11 CATS FIRST\n",
    "    COLS = list(train.columns[1:])\n",
    "    COLS = ['customer_ID'] + CATS + [c for c in COLS if c not in CATS]\n",
    "    train = train[COLS]\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1a110-d38c-4e68-abc4-0c4e02690103",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROCESS_DATA:\n",
    "    # CREATE PROCESSED TRAIN FILES AND SAVE TO DISK        \n",
    "    for k in range(NUM_FILES):\n",
    "\n",
    "        # READ CHUNK OF TRAIN CSV FILE\n",
    "        skip = int(np.sum( rows[:k] ) + 1) #the plus one is for skipping header\n",
    "        train = cudf.read_csv('../input/amex-default-prediction/train_data.csv', nrows=rows[k], \n",
    "                              skiprows=skip, header=None, names=T_COLS)\n",
    "\n",
    "        # FEATURE ENGINEER DATAFRAME\n",
    "        train = feature_engineer(train, targets = targets)\n",
    "\n",
    "        # SAVE FILES\n",
    "        print(f'Train_File_{k+1} has {train.customer_ID.nunique()} customers and shape',train.shape)\n",
    "        tar = train[['customer_ID','target']].drop_duplicates().sort_index()\n",
    "        if not os.path.exists(PATH_TO_DATA): os.makedirs(PATH_TO_DATA)\n",
    "        tar.to_parquet(f'{PATH_TO_DATA}targets_{k+1}.pqt',index=False)\n",
    "        data = train.iloc[:,1:-1].values.reshape((-1,13,188))\n",
    "        cupy.save(f'{PATH_TO_DATA}data_{k+1}',data.astype('float32'))\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del train, tar, data\n",
    "    del targets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b979c-cdf9-431f-bfad-280aa5717868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074867f-919d-49fa-ae34-bb962debcccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudf_torch",
   "language": "python",
   "name": "cudf_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
