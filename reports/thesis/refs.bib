% Outliers, winsorization
@article{winsorization,
    title = {The effects of handling outliers on the performance of bankruptcy prediction models},
    journal = {Socio-Economic Planning Sciences},
    volume = {67},
    pages = {34-42},
    year = {2019},
    issn = {0038-0121},
    doi = {https://doi.org/10.1016/j.seps.2018.08.004},
    url = {https://www.sciencedirect.com/science/article/pii/S003801211730232X},
    author = {Tamás Nyitrai and Miklós Virág},
    keywords = {Bankruptcy prediction, Data preprocessing, Winsorizing, Decision trees, CHAID, CART, Neural networks}
}

% For the change of variables formula
@book{murphy,
    added-at = {2017-02-27T11:22:42.000+0100},
    address = {Cambridge, Mass. [u.a.]},
    author = {Murphy, Kevin P.},
    biburl = {https://www.bibsonomy.org/bibtex/270148d65a6a66e0ae962bf22c5f66148/hotho},
    description = {Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series): Kevin P. Murphy: 9780262018029: Amazon.com: Books},
    interhash = {e99d8a06cc36507b05c38192ab80573e},
    intrahash = {70148d65a6a66e0ae962bf22c5f66148},
    isbn = {9780262018029 0262018020},
    keywords = {hmm lda learning machine statistics},
    publisher = {MIT Press},
    refid = {904442949},
    timestamp = {2017-02-27T11:22:42.000+0100},
    title = {Machine learning : a probabilistic perspective},
    url = {https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/ref=sr_1_2?ie=UTF8&qid=1336857747&sr=8-2},
    year = 2013
}
@article{normalizing_flows,
    doi = {10.1109/tpami.2020.2992934},
    url = {https://doi.org/10.1109%2Ftpami.2020.2992934},
    year = 2021,
    month = {nov},
    publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
    volume = {43},
    number = {11},
    pages = {3964--3979},
    author = {Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker},
    title = {Normalizing Flows: An Introduction and Review of Current Methods},
    journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

@article{yeoJohnson,
    ISSN = {00063444},
    URL = {http://www.jstor.org/stable/2673623},
    abstract = {We introduce a new power transformation family which is well defined on the whole real line and which is appropriate for reducing skewness and to approximate normality. It has properties similar to those of the Box-Cox transformation for positive variables. The large-sample properties of the transformation are investigated in the contect of a single random sample},
    author = {In-Kwon Yeo and Richard A. Johnson},
    journal = {Biometrika},
    number = {4},
    pages = {954--959},
    publisher = {[Oxford University Press, Biometrika Trust]},
    title = {A New Family of Power Transformations to Improve Normality or Symmetry},
    urldate = {2023-08-04},
    volume = {87},
    year = {2000}
}

@article{rdain,
    author={Passalis, Nikolaos
            and Kanniainen, Juho
            and Gabbouj, Moncef
            and Iosifidis, Alexandros
            and Tefas, Anastasios},
    title={Forecasting Financial Time Series Using Robust Deep Adaptive Input Normalization},
    journal={Journal of Signal Processing Systems},
    year={2021},
    month={Oct},
    day={01},
    volume={93},
    number={10},
    pages={1235-1251},
    issn={1939-8115},
    doi={10.1007/s11265-020-01624-0},
    url={https://doi.org/10.1007/s11265-020-01624-0}
}

@article{dain,
    title={Deep Adaptive Input Normalization for Time Series Forecasting}, 
    author={Nikolaos Passalis and Anastasios Tefas and Juho Kanniainen and Moncef Gabbouj and Alexandros Iosifidis},
    year={2019},
    eprint={1902.07892},
    journal={arXiv preprint arXiv:1902.07892},
    archivePrefix={arXiv},
    primaryClass={q-fin.CP}
}

@article{bin,
    title={Bilinear Input Normalization for Neural Networks in Financial Forecasting}, 
    author={Dat Thanh Tran and Juho Kanniainen and Moncef Gabbouj and Alexandros Iosifidis},
    year={2021},
    journal={arXiv preprint arXiv:2109.00983},
    archivePrefix={arXiv},
    primaryClass={q-fin.ST}
}

@article{mixture_ct,
    author = {Cao, Zheng and Gao, Xiang and Chang, Yankui and Liu, Gongfa and Pei, Yuanji},
    year = {2023},
    month = {04},
    pages = {e14004},
    title = {Improving synthetic CT accuracy by combining the benefits of multiple normalized preprocesses},
    journal = {Journal of applied clinical medical physics},
    doi = {10.1002/acm2.14004}
}

@article{preprocess_origin,
    author = {Sola, J. and Sevilla, Joaquin},
    year = {1997},
    month = {07},
    pages = {1464 - 1468},
    title = {Importance of input data normalization for the application of neural networks to complex industrial problems},
    volume = {44},
    journal = {Nuclear Science, IEEE Transactions on},
    doi = {10.1109/23.589532}
}

@article{singh,
    title = {Investigating the impact of data normalization on classification performance},
    journal = {Applied Soft Computing},
    volume = {97},
    pages = {105524},
    year = {2020},
    issn = {1568-4946},
    doi = {https://doi.org/10.1016/j.asoc.2019.105524},
    url = {https://www.sciencedirect.com/science/article/pii/S1568494619302947},
    author = {Dalwinder Singh and Birmohan Singh},
    keywords = {Ant lion optimization, Data normalization, Feature selection, Feature weighting, -NN classifier}
}

@article{nawi,
    title = {The Effect of Data Pre-processing on Optimized Training of Artificial Neural Networks},
    journal = {Procedia Technology},
    volume = {11},
    pages = {32-39},
    year = {2013},
    note = {4th International Conference on Electrical Engineering and Informatics, ICEEI 2013},
    issn = {2212-0173},
    doi = {https://doi.org/10.1016/j.protcy.2013.12.159},
    url = {https://www.sciencedirect.com/science/article/pii/S2212017313003137},
    author = {Nazri Mohd Nawi and Walid Hasen Atomi and M.Z. Rehman},
    keywords = {Artificial neural networks, back propagation, gradient descent, gain value, pre-processing data}
}

@inproceedings{stanislav,
    author={Koval, Stanislav I.},
    booktitle={2018 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)}, 
    title={Data preparation for neural network data analysis}, 
    year={2018},
    volume={},
    number={},
    pages={898-901},
    doi={10.1109/EIConRus.2018.8317233}
}


@article{boxcox,
    ISSN = {00359246},
    URL = {http://www.jstor.org/stable/2984418},
    abstract = {In the analysis of data it is often assumed that observations y1, y2, ..., yn are independently normally distributed with constant variance and with expectations specified by a model linear in a set of parameters θ. In this paper we make the less restrictive assumption that such a normal, homoscedastic, linear model is appropriate after some suitable transformation has been applied to the y's. Inferences about the transformation and about the parameters of the linear model are made by computing the likelihood function and the relevant posterior distribution. The contributions of normality, homoscedasticity and additivity to the transformation are separated. The relation of the present methods to earlier procedures for finding transformations is discussed. The methods are illustrated with examples.},
    author = {G. E. P. Box and D. R. Cox},
    journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
    number = {2},
    pages = {211--252},
    publisher = {[Royal Statistical Society, Wiley]},
    title = {An Analysis of Transformations},
    urldate = {2023-08-07},
    volume = {26},
    year = {1964}
}

@misc{shape,
    title = {Measures of Shape: Skewness and Kurtosis},
    howpublished = {\url{http://brownmath.com/stat/shape.htm}},
    note = {Accessed: 2023-08-09},
    author = {Stan Brown},
    year = 2022,
    urldate = {2023-08-09},
}

@Inbook{kmeans,
    author="Jin, Xin
    and Han, Jiawei",
    editor="Sammut, Claude
    and Webb, Geoffrey I.",
    title="K-Means Clustering",
    bookTitle="Encyclopedia of Machine Learning",
    year="2010",
    publisher="Springer US",
    address="Boston, MA",
    pages="563--564",
    isbn="978-0-387-30164-8",
    doi="10.1007/978-0-387-30164-8_425",
    url="https://doi.org/10.1007/978-0-387-30164-8_425"
}


@book{mackay,
    added-at = {2007-05-24T14:43:04.000+0200},
    author = {MacKay, David J. C.},
    biburl = {https://www.bibsonomy.org/bibtex/24c23fea472f6e75c0964badd83883d77/tmalsburg},
    interhash = {86f621d9d6f9f159448f768d792d4511},
    intrahash = {4c23fea472f6e75c0964badd83883d77},
    keywords = {bayesianinference book informationtheory neuralnetworks patternrecognition probabilitytheory},
    publisher = {Copyright Cambridge University Press},
    timestamp = {2007-05-24T14:43:04.000+0200},
    title = {Information Theory, Inference, and Learning Algorithms},
    year = 2003
}

@misc{hierarchical_clustering,
    author = "{Wikipedia contributors}",
    title = "Hierarchical clustering --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2023",
    howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Hierarchical_clustering&oldid=1163178180}",
    note = "[Online; accessed 9-August-2023]"
}

@inproceedings{gru,
    title = "Empirical evaluation of gated recurrent neural networks on sequence modeling",
    author = "Junyoung Chung and Caglar Gulcehre and Kyunghyun Cho and Yoshua Bengio",
    year = "2014",
    language = "English (US)",
    booktitle = "NIPS 2014 Workshop on Deep Learning, December 2014",

}

@article{dnn,
    doi = {10.1016/j.neunet.2014.09.003},
    url = {https://doi.org/10.1016%2Fj.neunet.2014.09.003},
    year = 2015,
    month = {jan},
    publisher = {Elsevier {BV}},
    volume = {61},
    pages = {85--117},
    author = {Jürgen Schmidhuber},
    title = {Deep learning in neural networks: An overview},
    journal = {Neural Networks}
}

@inproceedings{backprop,
    author={Hecht-Nielsen},
    booktitle={International 1989 Joint Conference on Neural Networks}, 
    title={Theory of the backpropagation neural network}, 
    year={1989},
    volume={},
    number={},
    pages={593-605 vol.1},
    doi={10.1109/IJCNN.1989.118638}
}
